# Gradient Boosting

Gradient boosting is an ensemble method similar to AdaBoost, with the difference being that gradient boosting tries to fit the new predictor to the residual errors generated by the previous predictor.

In this folder, we use gradient boosting on the [boston housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html "Title") to predict the housing prices in Boston. There are 14 attributes, which can be found in this [description of the dataset] (https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html "Title").